
# ğŸ¤– RAG Chatbot: Document-Based Q&A System

---

## ğŸ“„ Overview

This project is a smart chatbot that answers user queries based only on a specific PDF document (like Terms & Conditions).  
It uses **Retrieval-Augmented Generation (RAG)**, combining semantic search (via embeddings and FAISS vector database) with a large language model (LLM) to deliver accurate, transparent, and grounded answers through a real-time Streamlit web interface.

---

## âœ¨ Features

- ğŸ“‘ **Document-grounded Q&A:** Answers come strictly from your uploaded document(s), no outside data.
- ğŸ§  **Semantic search:** Uses pre-trained embeddings (e.g., all-MiniLM-L6-v2) and a vector database (FAISS) for highly relevant text retrieval.
- ğŸ¤ **LLM-powered generation:** Utilizes models like Gemma, Mistral, or Llama (via Groq API) to generate natural, context-aware responses.
- âš¡ **Real-time chat:** Streamlit web app streams responses as they are generated, for a conversational, interactive experience.
- ğŸ” **Transparency:** Highlights which chunks of the document were used for each answer.

---

## ğŸ—‚ï¸ Project Structure

```
â”œâ”€â”€ data_cleaning.ipynb       # ğŸ§¹ Cleans and chunks the PDF document text
â”œâ”€â”€ embedding.ipynb           # ğŸ§¬ Converts text chunks to vector embeddings and builds vector DB (FAISS)
â”œâ”€â”€ generator.py              # ğŸ¤– Connects to LLM (via Groq) for grounded answer generation
â”œâ”€â”€ pipeline.py               # ğŸ”— Runs retrieval, prompt construction, and answer generation pipeline
â”œâ”€â”€ app.py                    # ğŸ’¬ Streamlit app with live chat UI
â””â”€â”€ AI_Training_Document.pdf  # ğŸ“„ Example PDF document (upload your own as needed)
```

---

## ğŸ”¬ How It Works (Deep Dive)

1. âœ‚ï¸ **Chunking:** Splits PDF into small, language-aware segments for fine-grained retrieval.
2. ğŸ§¬ **Embedding:** Uses transformer models to convert each chunk into a high-dimensional vector representing its meaning.
3. ğŸ“¦ **Indexing:** Embedding vectors are stored in FAISS for fast similarity search.
4. ğŸ” **Retrieval:** On user query, the system computes the queryâ€™s embedding and retrieves the k-most relevant chunks from FAISS.
5. ğŸ“ **Prompt Construction:** Gathers the query and retrieved chunks into a formatted prompt template.
6. ğŸ¤– **LLM Generation:** Sends the prompt to the selected LLM API; answer is generated â€˜groundedâ€™ in the retrieved evidence only.
7. ğŸ’¬ **UI:** Streams answer to web chat, highlighting which document chunks were referenced for maximum transparency.

---

## ğŸ§© Example Usage

**User:** â€œWhat penalties are there for late payment?â€
- ğŸ“„ The app finds related regulations in your document, sends them to the LLM, and immediately streams an answerâ€”**citing the exact paragraphs used.**

---

## ğŸ“ˆ Extending & Customizing

- ğŸ—ƒï¸ **Support for multi-PDF corpora:** Track documents and chunk sources, concatenate multiple embeddings, or shard by document domain.
- ğŸ”„ **Swap LLM APIs:** Abstract the `generator.py` logic to use OpenAI, Anthropic, or local LLMs.
- âš™ï¸ **Embed better:** Swap out embedding models for domain-tuned ones.
- ğŸ§© **Improve prompt engineering:** Modify the template for greater control or to add citation formatting.
- ğŸ’ **Frontend tweaks:** Refine Streamlitâ€™s UI/UX or migrate to React for more features.

---

## ğŸ›¡ï¸ Security & Privacy

- ğŸ”’ All documents and chats stay on your own infrastructure.
- ğŸ” (Optional) Add user authentication or data redaction per organization policy.

---

## ğŸ§ª Testing & Evaluation

- ğŸ“ Includes sample queries in `tests/` (add as needed).
- ğŸ“Š Use retrieval and answer correctness metrics (accuracy, recall, response groundedness).
- ğŸ§© Add end-to-end integration tests with Streamlitâ€™s testing tools.

---

## ğŸ“š Dependencies

- ğŸ python >= 3.9
- ğŸˆ streamlit
- ğŸ§¬ sentence-transformers
- ğŸ“¦ faiss-cpu
- ğŸ“„ pypdf / pdfplumber
- ğŸŒ requests
- (plus LLM API dependencies, e.g., groq, openai)

---